{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# in this notebook, i will try to establish understanding of data, and implement logistic regression of data.\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# some necessary libraries and packages\nimport sys\nimport matplotlib\nimport scipy as sp\nimport IPython \nfrom IPython import display\nimport sklearn\n\nimport random\nimport time\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data modelling libraries\n\n# modeling algorithm\nfrom sklearn import linear_model\n\n# model helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n# visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\n\n#config the visualisers\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw = pd.read_csv('/kaggle/input/titanic/train.csv')\ndata_val = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ndata1 = data_raw.copy(deep = True) # any cange in one, will not affect other. \n\ndata_cleaner = [data1, data_val] # both train and test combined in \n\nprint(data_raw.info())\ndata_raw.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking null elements in each feature\nprint('train columns with null values : \\n', data1.isnull().sum())\nprint(\"_\"*10)\n\nprint('test/val columns with null values : \\n', data_val.isnull().sum())\nprint(\"_\"*10)\n\ndata_raw.describe(include ='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# impute the following columns\n# Age with median \n# Embarked with Mode\n# Fare with Median\nfor dataset in data_cleaner:\n    dataset['Age'].fillna(dataset['Age'].median(), inplace= True)\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace= True)\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace= True)\n    \ndrop_columns = ['PassengerId','Cabin','Ticket']\ndata1.drop(drop_columns, axis=1, inplace =True)\n\nprint(data1.isnull().sum())\nprint('_'*10)\nprint(data_val.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# craete new features, train and test/val data set\n# family size -> no of members in family\n# alone -> if was alone or not\n# title -> includes Mr, Mrs, master .....\nfor dataset in data_cleaner :\n    dataset['FamilySize'] = dataset['SibSp']+dataset['Parch'] + 1\n    \n    # init alone \n    dataset['IsAlone'] = 1\n    dataset['IsAlone'].loc[dataset['FamilySize']>1] = 0 # ip values in  IsAlone\n    \n    # for title, str.split is used. \n    # Cumings, Mrs. John Bradley (Florence Briggs Thayer) ,is the entry\n    # first split around \", \"  and then select the second part\n    # Mrs. John Bradley (Florence Briggs Thayer)\n    # now split around \".\" and take the first part --> Mrs\n    dataset['Title'] = dataset['Name'].str.split(\", \",expand=True)[1].str.split(\".\",expand=True)[0]\n    \n    #craeting 4 farebins, ie. fare is now divided in 4 parts, qcut is used here,\n    #because, it depends on freq, hence tries to have almost same no of data\n    # in each bin. used in cases like below, where fares must be rather fixed already in a few slots. \n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n    \n    #craeting bins for age . cut is used here and is generally used for Age. \n    # it creates bins without considering frequency of data, hence might have different \n    # no of data in different bins\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['Title'].value_counts()\n# as we can see here, to many titles are present, and may not prove to be helpful\n# hence we will convert them to Misc (ie. miscillanious)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_min =10\ntitle_names = (data1['Title'].value_counts()<stat_min)\n#print(title_names)\n#print('_'*10)\n\ndata1['Title'] = data1['Title'].apply(lambda x: 'Misc'\n                                     if title_names.loc[x]==True else x)\nprint(data1['Title'].value_counts())\nprint('_'*10)\n\ntitle_names_val = (data_val['Title'].value_counts()<stat_min)\n#print(title_names)\n#print('_'*10)\n\ndata_val['Title'] = data_val['Title'].apply(lambda x: 'Misc'\n                                     if title_names_val.loc[x]==True else x)\nprint(data_val['Title'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputed datas !!!!\ndata1.info()\ndata_val.info()\ndata1.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we will work on  --  converting formats !\n# ie. convert catagorical data into mathematical data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = LabelEncoder()\nfor dataset in data_cleaner:\n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n    \n# define y variable\nTarget = ['Survived']\ndata1_x = ['Sex','Pclass','Embarked','Title','SibSp','Parch','Age','Fare','FamilySize','IsAlone']\n\ndata1_xy = Target+data1_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split !!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Exploratory analysis \n# group by, groups elements on basis of index passedin groupby\nfor x in data1_x:\n    if data1[x].dtype!='float64' :\n        print(\"Survival correlation by :\",x)\n        print(data1[[x,Target[0]]].groupby(x).mean())\n        print('_'*13,'\\n')\n        \nprint(pd.crosstab(data1['Title'],data1[Target[0]]))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting different types of plots and analysing them\n\nplt.figure(figsize=[16,12])\n\nplt.subplot(231)\nplt.boxplot(x=data1['Fare'],showmeans = True, meanline=True)\nplt.title(\"Fare Boxplot\")\nplt.ylabel(\"Fare ($)\")\n\nplt.subplot(232)\nplt.boxplot(x=data1['Age'],showmeans = True, meanline=True)\nplt.title(\"Age Boxplot\")\nplt.ylabel(\"Age (years)\")\n\nplt.subplot(233)\nplt.boxplot(x=data1['FamilySize'],showmeans = True, meanline=True)\nplt.title(\"Family Size Boxplot\")\nplt.ylabel(\"Family Size (#)\")\n\nplt.subplot(234)\nplt.hist(x=[data1[data1['Survived']==1]['Fare'] , data1[data1['Survived']==0]['Fare']],\n        stacked=True, color=['g','r'], label=['Survived','Dead'])\nplt.title(\"Fare hist by Survival\")\nplt.xlabel('Fare($)')\nplt.ylabel('# of passengers')\nplt.legend()\n\nplt.subplot(235)\nplt.hist(x=[data1[data1['Survived']==1]['Age'] , data1[data1['Survived']==0]['Age']],\n        stacked=True, color=['g','r'], label=['Survived','Dead'])\nplt.title(\"Age hist by Survival\")\nplt.xlabel('Age(years)')\nplt.ylabel('# of passengers')\nplt.legend()\n\nplt.subplot(236)\nplt.hist(x=[data1[data1['Survived']==1]['FamilySize'] , data1[data1['Survived']==0]['FamilySize']],\n        stacked=True, color=['g','r'], label=['Survived','Dead'])\nplt.title(\"Family Size hist by Survival\")\nplt.xlabel('Family Size(#)')\nplt.ylabel('# of passengers')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , saxis = plt.subplots(2,3,figsize=(16,12))\n\n# bar plots with sns \nsns.barplot(x='Embarked',y='Survived', data=data1,ax=saxis[0,0])\nsns.barplot(x='Pclass', y='Survived', order = [1,2,3], data=data1, ax=saxis[0,1])\nsns.barplot(x='IsAlone',y='Survived', order=[1,0],data=data1,ax=saxis[0,2])\n\n#point plots with sns\nsns.pointplot(x='FareBin',y='Survived', data=data1,ax=saxis[1,0])\nsns.pointplot(x='AgeBin',y='Survived', data=data1,ax=saxis[1,1])\nsns.pointplot(x='FamilySize',y='Survived', data=data1,ax=saxis[1,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\n#boxplots and violin plotss for- grapg distribution of qualitative data\n\nsns.boxplot(x='Pclass',y='Fare',hue='Survived',data=data1,ax=axis1)\naxis1.set_title('Pclass vs Fare Survival comparision')\n\nsns.violinplot(x='Pclass',y='Age',hue='Survived',data=data1,split=True,ax=axis2)\naxis2.set_title('Pclass vs Age Survival comparision')\n\nsns.boxplot(x='Pclass',y='FamilySize',hue='Survived',data=data1,ax=axis3)\naxis3.set_title('Pclass vs FamilySize Survival comparision')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# distributionto study relation with sex\n\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x='Sex',y='Survived',hue='Embarked',data=data1,ax=qaxis[0])\naxis1.set_title('Sex vs Embarked Survival Comparision')\n\nsns.barplot(x='Sex',y='Survived',hue='Pclass',data=data1,ax=qaxis[1])\naxis1.set_title('Sex vs Pclass Survival Comparision')\n\nsns.barplot(x='Sex',y='Survived',hue='IsAlone',data=data1,ax=qaxis[2])\naxis1.set_title('Sex vs IsAlone Survival Comparision')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#more side-by-side comparisons\nfig, (maxis1, maxis2) = plt.subplots(1, 2,figsize=(14,12))\n\n#how does family size factor with sex & survival compare\nsns.pointplot(x=\"FamilySize\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"], ax = maxis1)\n\n#how does class factor with sex & survival compare\nsns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data1,\n              palette={\"male\": \"blue\", \"female\": \"pink\"},\n              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"], ax = maxis2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#how does embark port factor with class, sex, and survival compare\n#facetgrid: https://seaborn.pydata.org/generated/seaborn.FacetGrid.html\ne = sns.FacetGrid(data1, col = 'Embarked') # alternative of subplot\ne.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette = 'deep')\ne.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = sns.FacetGrid( data1, hue = 'Survived', aspect=4 )\na.map(sns.kdeplot, 'Age', shade= True )\na.set(xlim=(0 , data1['Age'].max()))\na.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = sns.FacetGrid(data1, row = 'Sex', col = 'Pclass', hue = 'Survived')\nh.map(plt.hist, 'Age', alpha = .75)\nh.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#elements = ['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked',\n#           'FamilySize','IsAlone','FareBin','AgeBin','Sex_Code','Embarked_Code','Title_Code',\n#           'AgeBin_Code','FareBin_Code']\n\nelements = ['Survived','Pclass','Age','FamilySize','IsAlone','SibSp','Fare'\n           ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsns.pairplot(data1[elements],hue='Survived',plot_kws={'alpha':.4,'s':60,'edgecolor':'k'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = data1.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(data1[top_corr_features].corr(),annot=True,\n              cmap='RdYlGn')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using sklearn to train LR\nfrom sklearn.model_selection import train_test_split \nfeatures = ['Pclass','Age','SibSp','Parch','Fare','FamilySize','IsAlone','Sex_Code','Embarked_Code','Title_Code']\nX = data1[features]\ny = data1['Survived']\n\nX_tr,X_te,y_tr,y_te = train_test_split(X,y,test_size=.2)\n\nX_t = data_val[features]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_te.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling data with sklearn \nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\n# data for our analysis \nX_train_scaled = scaler.fit_transform(X_tr)\nX_test_scaled = scaler.transform(X_te)\n\n# actual problems text data\nX_TEST_scaled = scaler.transform(X_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking is scaling worked !!\n\n#plt.hist(X_tr[:,1:2])\nX_tr['Age'].hist()\nX_t['Age'].hist()\n\nplt.show()\nplt.hist(X_train_scaled[:,1:2])\nplt.hist(X_TEST_scaled[:,1:2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying Logistic Regreasion \n\nfrom sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression()\n\nLR.fit(X_train_scaled,y_tr)\n\nprediction = LR.predict(X_test_scaled)\nprint(prediction)\nprint(y_te)\nscore = LR.score(X_test_scaled,y_te)\nprint(score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}