{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# in this notebook, i will try to establish understanding of data, and implement logistic regression of data.\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# some necessary libraries and packages\nimport sys\nimport matplotlib\nimport scipy as sp\nimport IPython \nfrom IPython import display\nimport sklearn\n\nimport random\nimport time\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data modelling libraries\n\n# modeling algorithm\nfrom sklearn import linear_model\n\n# model helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n# visualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\n\n#config the visualisers\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw = pd.read_csv('/kaggle/input/titanic/train.csv')\ndata_val = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ndata1 = data_raw.copy(deep = True) # any cange in one, will not affect other. \n\ndata_cleaner = [data1, data_val] # both train and test combined in \n\nprint(data_raw.info())\ndata_raw.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking null elements in each feature\nprint('train columns with null values : \\n', data1.isnull().sum())\nprint(\"_\"*10)\n\nprint('test/val columns with null values : \\n', data_val.isnull().sum())\nprint(\"_\"*10)\n\ndata_raw.describe(include ='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# impute the following columns\n# Age with median \n# Embarked with Mode\n# Fare with Median\nfor dataset in data_cleaner:\n    dataset['Age'].fillna(dataset['Age'].median(), inplace= True)\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace= True)\n    dataset['Fare'].fillna(dataset['Fare'].median(), inplace= True)\n    \ndrop_columns = ['PassengerId','Cabin','Ticket']\ndata1.drop(drop_columns, axis=1, inplace =True)\n\nprint(data1.isnull().sum())\nprint('_'*10)\nprint(data_val.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# craete new features, train and test/val data set\n# family size -> no of members in family\n# alone -> if was alone or not\n# title -> includes Mr, Mrs, master .....\nfor dataset in data_cleaner :\n    dataset['FamilySize'] = dataset['SibSp']+dataset['Parch'] + 1\n    \n    # init alone \n    dataset['IsAlone'] = 1\n    dataset['IsAlone'].loc[dataset['FamilySize']>1] = 0 # ip values in  IsAlone\n    \n    # for title, str.split is used. \n    # Cumings, Mrs. John Bradley (Florence Briggs Thayer) ,is the entry\n    # first split around \", \"  and then select the second part\n    # Mrs. John Bradley (Florence Briggs Thayer)\n    # now split around \".\" and take the first part --> Mrs\n    dataset['Title'] = dataset['Name'].str.split(\", \",expand=True)[1].str.split(\".\",expand=True)[0]\n    \n    #craeting 4 farebins, ie. fare is now divided in 4 parts, qcut is used here,\n    #because, it depends on freq, hence tries to have almost same no of data\n    # in each bin. used in cases like below, where fares must be rather fixed already in a few slots. \n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n    \n    #craeting bins for age . cut is used here and is generally used for Age. \n    # it creates bins without considering frequency of data, hence might have different \n    # no of data in different bins\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['Title'].value_counts()\n# as we can see here, to many titles are present, and may not prove to be helpful\n# hence we will convert them to Misc (ie. miscillanious)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stat_min =10\ntitle_names = (data1['Title'].value_counts()<stat_min)\n#print(title_names)\n#print('_'*10)\n\ndata1['Title'] = data1['Title'].apply(lambda x: 'Misc'\n                                     if title_names.loc[x]==True else x)\nprint(data1['Title'].value_counts())\nprint('_'*10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imputed datas !!!!\ndata1.info()\ndata_val.info()\ndata1.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now we will work on  --  converting formats !\n# ie. convert catagorical data into mathematical data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label = LabelEncoder()\nfor dataset in data_cleaner:\n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n    \n# define y variable\nTarget = ['Survived']\ndata1_x = ['Sex','Pclass','Embarked','Title','SibSp','Parch','Age','Fare','FamilySize','IsAlone']\n\ndata1_xy = Target+data1_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train test split !!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Exploratory analysis \n# group by, groups elements on basis of index passedin groupby\nfor x in data1_x:\n    if data1[x].dtype!='float64' :\n        print(\"Survival correlation by :\",x)\n        print(data1[[x,Target[0]]].groupby(x).mean())\n        print('_'*13,'\\n')\n        \nprint(pd.crosstab(data1['Title'],data1[Target[0]]))\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting different types of plots and analysing them\n\nplt.figure(figsize=[16,12])\n\nplt.subplot(231)\nplt.boxplot(x=data1['Fare'],showmeans = True, meanline=True)\nplt.title(\"Fare Boxplot\")\nplt.ylabel(\"Fare ($)\")\n\nplt.subplot(232)\nplt.boxplot(x=data1['Age'],showmeans = True, meanline=True)\nplt.title(\"Age Boxplot\")\nplt.ylabel(\"Age (years)\")\n\nplt.subplot(233)\nplt.boxplot(x=data1['FamilySize'],showmeans = True, meanline=True)\nplt.title(\"Family Size Boxplot\")\nplt.ylabel(\"Family Size (#)\")\n\nplt.subplot(234)\nplt.hist(x=[data1[data1['Survived']==1]['Fare'] , data1[data1['Survived']==0]['Fare']],\n        stacked=True, color=['g','r'], label=['Survived','Dead'])\nplt.title(\"Fare hist by Survival\")\nplt.xlabel('Fare($)')\nplt.ylabel('# of passengers')\nplt.legend()\n\nplt.subplot(235)\nplt.hist(x=[data1[data1['Survived']==1]['Age'] , data1[data1['Survived']==0]['Age']],\n        stacked=True, color=['g','r'], label=['Survived','Dead'])\nplt.title(\"Age hist by Survival\")\nplt.xlabel('Age(years)')\nplt.ylabel('# of passengers')\nplt.legend()\n\nplt.subplot(236)\nplt.hist(x=[data1[data1['Survived']==1]['FamilySize'] , data1[data1['Survived']==0]['FamilySize']],\n        stacked=True, color=['g','r'], label=['Survived','Dead'])\nplt.title(\"Family Size hist by Survival\")\nplt.xlabel('Family Size(#)')\nplt.ylabel('# of passengers')\nplt.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}